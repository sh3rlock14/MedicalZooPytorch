Starting a run with:
{'data_params': {'augmentation': False,
                 'classes': 4,
                 'data_path': 'D:/LaureaMagistrale/Tesi Magistrale/MICCAI '
                              'Data/',
                 'dataset': 'brats2018',
                 'load': False,
                 'normalization': 'full_volume_mean',
                 'num_workers': 0,
                 'split': 0.8,
                 'threshold': 1e-11,
                 'train_batch_size': 4,
                 'vol_crop_dim': [32, 32, 32],
                 'vol_train_samples': 32,
                 'vol_val_samples': 4},
 'exp_params': {'alpha': 0.99,
                'inChannels': 4,
                'inModalities': 4,
                'lr': 0.00011281280998762527,
                'momentum': 0.8057442393137866,
                'num_iters': 100,
                'weight_decay': 0.018463614897243495},
 'model_params': {'base_n_filter': 8, 'in_channels': 4, 'n_classes': 4},
 'sweep_params': {'ntrials': 1,
                  'project': 'MICCAI 2018 Medical Image Segmentation'},
 'trainer_params': {'accelerator': 'gpu',
                    'devices': 1,
                    'limit_val_batches': 0,
                    'log_every_n_steps': 50,
                    'max_steps': 100,
                    'max_time': '00:00:10:00',
                    'num_sanity_val_steps': 0,
                    'val_check_interval': 0.5},
 'training_params': {'ckpt_path': None,
                     'debug': True,
                     'n_models_to_save': 10,
                     'resume_train': False},
 'wandb_params': {'ckpt_name': 'UNet3D',
                  'manual_seed': 42,
                  'model_name': 'UNet3D',
                  'save_dir': 'D:/LaureaMagistrale/MedicalZooPytorch/results/logs'}}
Mode: train Subvolume samples to generate:  32  Volumes:  195
Mode: val Subvolume samples to generate:  4  Volumes:  90
D:\IDEs\anaconda3\envs\AML\lib\site-packages\pytorch_lightning\loggers\wandb.py:352: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.
  rank_zero_warn(
So far so good!
====== Starting Training UNet3D from scratch ======
Mode: train Subvolume samples to generate:  32  Volumes:  195
Mode: val Subvolume samples to generate:  4  Volumes:  90
Sanity Checking: 0it [00:00, ?it/s]
D:\IDEs\anaconda3\envs\AML\lib\site-packages\pytorch_lightning\trainer\connectors\data_connector.py:236: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.

Sanity Checking DataLoader 0:   0%|                           | 0/1 [00:00<?, ?it/s]Backend QtAgg is interactive backend. Turning interactive mode on.
Epoch 0:   0%|                                                | 0/9 [00:00<?, ?it/s]
D:\IDEs\anaconda3\envs\AML\lib\site-packages\pytorch_lightning\trainer\connectors\data_connector.py:236: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
D:\IDEs\anaconda3\envs\AML\lib\site-packages\pytorch_lightning\trainer\trainer.py:1892: PossibleUserWarning: The number of training batches (8) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
  rank_zero_warn(
D:\IDEs\anaconda3\envs\AML\lib\site-packages\pytorch_lightning\loops\optimization\optimizer_loop.py:135: UserWarning: `training_step` returned `None`. If this was on purpose, ignore this warning...





